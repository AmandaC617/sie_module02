import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime
import os
from typing import Dict, List, Optional

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from website_ai_readiness import run_website_analysis
from eeat_benchmarking import run_eeat_benchmarking
from eeat_module import run_module_2 as run_eeat_analysis

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="SIE å¹³å° - æ™ºèƒ½æœå°‹å¼•æ“å„ªåŒ–åˆ†æ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    .success-card {
        border-left-color: #28a745;
    }
    .warning-card {
        border-left-color: #ffc107;
    }
    .error-card {
        border-left-color: #dc3545;
    }
    .info-card {
        border-left-color: #17a2b8;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """ä¸»æ‡‰ç”¨ç¨‹å¼"""
    
    # å´é‚Šæ¬„é…ç½®
    with st.sidebar:
        st.title("ğŸš€ SIE å¹³å°")
        st.markdown("---")
        
        # API é‡‘é‘°è¨­å®š
        gemini_api_key = st.text_input(
            "ğŸ”‘ Gemini API é‡‘é‘°",
            type="password",
            help="è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ä»¥å•Ÿç”¨ AI å»ºè­°åŠŸèƒ½"
        )
        
        st.markdown("---")
        
        # é é¢é¸æ“‡
        page = st.selectbox(
            "ğŸ“„ é¸æ“‡åˆ†ææ¨¡çµ„",
            [
                "ğŸ  é¦–é ",
                "ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ",
                "ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ",
                "ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ",
                "ğŸ“ˆ åˆ†æå ±å‘Š"
            ]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ ä½¿ç”¨èªªæ˜")
        st.markdown("""
        1. **æ¨¡çµ„ 1**: åˆ†æç¶²ç«™æŠ€è¡“å¥åº·åº¦èˆ‡ AI å°±ç·’åº¦
        2. **æ¨¡çµ„ 2**: å‹•æ…‹ E-E-A-T è©•ä¼°èˆ‡ç«¶çˆ­åŸºæº–åˆ†æ
        3. **å®Œæ•´åˆ†æ**: å‚³çµ± E-E-A-T åˆ†æ
        4. **å ±å‘Š**: æŸ¥çœ‹æ­·å²åˆ†æçµæœ
        """)
    
    # ä¸»å…§å®¹å€åŸŸ
    if page == "ğŸ  é¦–é ":
        show_homepage()
    elif page == "ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ":
        show_module1_page(gemini_api_key)
    elif page == "ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ":
        show_module2_page(gemini_api_key)
    elif page == "ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ":
        show_full_eeat_page(gemini_api_key)
    elif page == "ğŸ“ˆ åˆ†æå ±å‘Š":
        show_reports_page()

def show_homepage():
    """é¡¯ç¤ºé¦–é """
    st.markdown('<div class="main-header">', unsafe_allow_html=True)
    st.title("ğŸš€ SIE å¹³å°")
    st.subtitle("æ™ºèƒ½æœå°‹å¼•æ“å„ªåŒ–åˆ†æç³»çµ±")
    st.markdown("</div>", unsafe_allow_html=True)
    
    # åŠŸèƒ½ä»‹ç´¹
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ")
        st.markdown("""
        - âœ… robots.txt èˆ‡ LLM éµå¾æ€§æª¢æŸ¥
        - âœ… sitemap.xml é©—è­‰
        - âœ… llms.txt å‰ç»æ€§æŒ‡æ¨™
        - âœ… HTTPS å®‰å…¨æ€§æª¢æŸ¥
        - âœ… å…§éƒ¨é€£çµçµæ§‹åˆ†æ
        - âœ… Schema.org çµæ§‹åŒ–è³‡æ–™æª¢æ¸¬
        - âœ… å…§å®¹å¯è®€æ€§è©•ä¼°
        - âœ… AI æŠ€è¡“å»ºè­°ç”Ÿæˆ
        """)
    
    with col2:
        st.markdown("### ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ")
        st.markdown("""
        - ğŸ¤– AI é ˜å°è€…è­˜åˆ¥èˆ‡åˆ†æ
        - ğŸ“Š å‹•æ…‹åª’é«”æ¬Šé‡è©•ä¼°
        - ğŸ† ç«¶çˆ­å°æ‰‹åŸºæº–åˆ†æ
        - ğŸ“ˆ è¶¨å‹¢è¿½è¹¤èˆ‡é æ¸¬
        - ğŸ¯ ç­–ç•¥å»ºè­°ç”Ÿæˆ
        - ğŸ“± ç¤¾äº¤åª’é«”æ¬Šå¨åˆ†æ
        - ğŸ“° åª’é«”æåŠç›£æ§
        - ğŸ”„ å¸‚å ´æ©Ÿæœƒè­˜åˆ¥
        """)
    
    st.markdown("---")
    
    # çµ±è¨ˆè³‡è¨Š
    st.markdown("### ğŸ“Š å¹³å°çµ±è¨ˆ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("åˆ†ææ¬¡æ•¸", "1,234", "+12%")
    
    with col2:
        st.metric("ç¶²ç«™åˆ†æ", "567", "+8%")
    
    with col3:
        st.metric("ç«¶çˆ­å°æ‰‹", "89", "+15%")
    
    with col4:
        st.metric("å»ºè­°ç”Ÿæˆ", "2,345", "+20%")

def show_module1_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºæ¨¡çµ„ 1 é é¢"""
    st.title("ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ")
    st.markdown("åˆ†æç¶²ç«™çš„æŠ€è¡“å¥åº·åº¦èˆ‡ AI å°±ç·’åº¦")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("module1_form"):
        website_url = st.text_input(
            "ğŸŒ ç¶²ç«™ URL",
            placeholder="ä¾‹å¦‚: example.com æˆ– https://example.com",
            help="è¼¸å…¥è¦åˆ†æçš„ç¶²ç«™ URL"
        )
        
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and website_url:
        with st.spinner("ğŸ” æ­£åœ¨åˆ†æç¶²ç«™ AI å°±ç·’åº¦..."):
            try:
                # åŸ·è¡Œåˆ†æ
                result = run_website_analysis(website_url, gemini_api_key)
                
                if "error" in result:
                    st.error(f"åˆ†æå¤±æ•—: {result['error']}")
                    return
                
                analysis_data = result.get("technical_seo_ai_readiness", {})
                
                # é¡¯ç¤ºåˆ†æçµæœ
                display_module1_results(analysis_data, website_url)
                
                # å„²å­˜çµæœ
                save_analysis_result("module1", website_url, result)
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def display_module1_results(analysis_data: Dict, website_url: str):
    """é¡¯ç¤ºæ¨¡çµ„ 1 åˆ†æçµæœ"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {website_url}")
    
    # ç¸½é«”è©•åˆ†
    col1, col2, col3 = st.columns(3)
    
    with col1:
        root_files = analysis_data.get("root_files", {})
        root_score = calculate_root_files_score(root_files)
        st.metric("æ ¹æª”æ¡ˆè©•åˆ†", f"{root_score}/100", "âœ…")
    
    with col2:
        architecture = analysis_data.get("architecture_signals", {})
        arch_score = calculate_architecture_score(architecture)
        st.metric("æ¶æ§‹è©•åˆ†", f"{arch_score}/100", "ğŸ—ï¸")
    
    with col3:
        llm_friendliness = analysis_data.get("llm_friendliness", {})
        llm_score = calculate_llm_friendliness_score(llm_friendliness)
        st.metric("LLM å‹å–„åº¦", f"{llm_score}/100", "ğŸ¤–")
    
    st.markdown("---")
    
    # è©³ç´°åˆ†æçµæœ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ æ ¹æª”æ¡ˆ", "ğŸ—ï¸ æ¶æ§‹", "ğŸ¤– LLM å‹å–„åº¦", "ğŸ’¡ å»ºè­°"])
    
    with tab1:
        display_root_files_analysis(analysis_data.get("root_files", {}))
    
    with tab2:
        display_architecture_analysis(analysis_data.get("architecture_signals", {}))
    
    with tab3:
        display_llm_friendliness_analysis(analysis_data.get("llm_friendliness", {}))
    
    with tab4:
        display_recommendations(analysis_data.get("actionable_recommendations", []))

def show_module2_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºæ¨¡çµ„ 2 é é¢"""
    st.title("ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ")
    st.markdown("å‹•æ…‹ E-E-A-T è©•ä¼°èˆ‡ç«¶çˆ­åŸºæº–åˆ†æ")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("module2_form"):
        target_website = st.text_input(
            "ğŸ¯ ç›®æ¨™ç¶²ç«™",
            placeholder="ä¾‹å¦‚: example.com",
            help="è¼¸å…¥è¦åˆ†æçš„ä¸»è¦ç¶²ç«™"
        )
        
        competitors = st.text_area(
            "ğŸ† ç«¶çˆ­å°æ‰‹ (æ¯è¡Œä¸€å€‹)",
            placeholder="competitor1.com\ncompetitor2.com\ncompetitor3.com",
            help="è¼¸å…¥ç«¶çˆ­å°æ‰‹ç¶²ç«™ï¼Œæ¯è¡Œä¸€å€‹"
        )
        
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and target_website:
        # è™•ç†ç«¶çˆ­å°æ‰‹åˆ—è¡¨
        competitor_list = []
        if competitors:
            competitor_list = [comp.strip() for comp in competitors.split('\n') if comp.strip()]
        
        with st.spinner("ğŸ” æ­£åœ¨åŸ·è¡Œ E-E-A-T åŸºæº–åˆ†æ..."):
            try:
                # åŸ·è¡Œåˆ†æ
                result = run_eeat_benchmarking(target_website, competitor_list, gemini_api_key)
                
                if "error" in result:
                    st.error(f"åˆ†æå¤±æ•—: {result['error']}")
                    return
                
                analysis_data = result.get("eeat_benchmarking", {})
                
                # é¡¯ç¤ºåˆ†æçµæœ
                display_module2_results(analysis_data, target_website)
                
                # å„²å­˜çµæœ
                save_analysis_result("module2", target_website, result)
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def display_module2_results(analysis_data: Dict, target_website: str):
    """é¡¯ç¤ºæ¨¡çµ„ 2 åˆ†æçµæœ"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {target_website}")
    
    # ç¸½é«”è©•åˆ†
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        ai_leader = analysis_data.get("ai_leader_analysis", {})
        ai_score = ai_leader.get("ai_leader_score", 0)
        st.metric("AI é ˜å°è€…åˆ†æ•¸", f"{ai_score}/100", "ğŸ¤–")
    
    with col2:
        media_weights = analysis_data.get("dynamic_media_weights", {})
        media_score = media_weights.get("media_mentions", {}).get("media_coverage_score", 0)
        st.metric("åª’é«”è¦†è“‹åˆ†æ•¸", f"{media_score:.1f}/100", "ğŸ“°")
    
    with col3:
        social_score = media_weights.get("social_media_presence", {}).get("social_authority_score", 0)
        st.metric("ç¤¾äº¤åª’é«”æ¬Šå¨", f"{social_score:.1f}/100", "ğŸ“±")
    
    with col4:
        competitor_bench = analysis_data.get("competitor_benchmarking", {})
        market_position = competitor_bench.get("market_position", "unknown")
        st.metric("å¸‚å ´åœ°ä½", market_position.title(), "ğŸ†")
    
    st.markdown("---")
    
    # è©³ç´°åˆ†æçµæœ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ¤– AI é ˜å°è€…", "ğŸ“Š åª’é«”æ¬Šé‡", "ğŸ† ç«¶çˆ­åˆ†æ", "ğŸ“ˆ è¶¨å‹¢", "ğŸ’¡ ç­–ç•¥"])
    
    with tab1:
        display_ai_leader_analysis(analysis_data.get("ai_leader_analysis", {}))
    
    with tab2:
        display_media_weights_analysis(analysis_data.get("dynamic_media_weights", {}))
    
    with tab3:
        display_competitor_analysis(analysis_data.get("competitor_benchmarking", {}))
    
    with tab4:
        display_trend_analysis(analysis_data.get("trend_analysis", {}))
    
    with tab5:
        display_strategic_recommendations(analysis_data.get("strategic_recommendations", []))

def show_full_eeat_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºå®Œæ•´ E-E-A-T åˆ†æé é¢"""
    st.title("ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ")
    st.markdown("å‚³çµ± E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness) åˆ†æ")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("full_eeat_form"):
        website_url = st.text_input(
            "ğŸŒ ç¶²ç«™ URL",
            placeholder="ä¾‹å¦‚: example.com",
            help="è¼¸å…¥è¦åˆ†æçš„ç¶²ç«™ URL"
        )
        
        company_name = st.text_input(
            "ğŸ¢ å…¬å¸åç¨±",
            placeholder="ä¾‹å¦‚: Example Corp",
            help="è¼¸å…¥å…¬å¸æˆ–çµ„ç¹”åç¨±"
        )
        
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and website_url and company_name:
        with st.spinner("ğŸ” æ­£åœ¨åŸ·è¡Œå®Œæ•´ E-E-A-T åˆ†æ..."):
            try:
                # åŸ·è¡Œåˆ†æ
                result = run_eeat_analysis(website_url, company_name, gemini_api_key)
                
                if "error" in result:
                    st.error(f"åˆ†æå¤±æ•—: {result['error']}")
                    return
                
                # é¡¯ç¤ºåˆ†æçµæœ
                display_full_eeat_results(result, website_url, company_name)
                
                # å„²å­˜çµæœ
                save_analysis_result("full_eeat", website_url, result)
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def display_full_eeat_results(result: Dict, website_url: str, company_name: str):
    """é¡¯ç¤ºå®Œæ•´ E-E-A-T åˆ†æçµæœ"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {company_name} ({website_url})")
    
    # ç¸½é«” E-E-A-T åˆ†æ•¸
    eeat_scores = result.get("eeat_scores", {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        experience_score = eeat_scores.get("experience", 0)
        st.metric("Experience", f"{experience_score}/100", "ğŸ“š")
    
    with col2:
        expertise_score = eeat_scores.get("expertise", 0)
        st.metric("Expertise", f"{expertise_score}/100", "ğŸ“")
    
    with col3:
        authoritativeness_score = eeat_scores.get("authoritativeness", 0)
        st.metric("Authoritativeness", f"{authoritativeness_score}/100", "ğŸ†")
    
    with col4:
        trustworthiness_score = eeat_scores.get("trustworthiness", 0)
        st.metric("Trustworthiness", f"{trustworthiness_score}/100", "âœ…")
    
    # é¡¯ç¤ºè©³ç´°åˆ†æçµæœ
    display_eeat_detailed_results(result)

def show_reports_page():
    """é¡¯ç¤ºåˆ†æå ±å‘Šé é¢"""
    st.title("ğŸ“ˆ åˆ†æå ±å‘Š")
    st.markdown("æŸ¥çœ‹æ­·å²åˆ†æçµæœèˆ‡è¶¨å‹¢")
    
    # è¼‰å…¥æ­·å²å ±å‘Š
    reports = load_analysis_reports()
    
    if not reports:
        st.info("ğŸ“ å°šç„¡åˆ†æå ±å‘Šï¼Œè«‹å…ˆåŸ·è¡Œåˆ†æ")
        return
    
    # å ±å‘Šåˆ—è¡¨
    for report in reports:
        with st.expander(f"ğŸ“Š {report['timestamp']} - {report['website']} ({report['module']})"):
            st.json(report['result'])

# è¼”åŠ©å‡½æ•¸
def calculate_root_files_score(root_files: Dict) -> int:
    """è¨ˆç®—æ ¹æª”æ¡ˆè©•åˆ†"""
    score = 0
    if root_files.get("has_robots_txt"):
        score += 25
    if root_files.get("robots_allows_ai_bots"):
        score += 25
    if root_files.get("has_sitemap_xml"):
        score += 25
    if root_files.get("sitemap_is_valid"):
        score += 15
    if root_files.get("has_llms_txt"):
        score += 10
    return score

def calculate_architecture_score(architecture: Dict) -> int:
    """è¨ˆç®—æ¶æ§‹è©•åˆ†"""
    score = 0
    if architecture.get("uses_https"):
        score += 30
    if architecture.get("internal_link_structure") == "good":
        score += 40
    elif architecture.get("internal_link_structure") == "fair":
        score += 20
    score += min(architecture.get("estimated_authority_links", 0) * 2, 30)
    return score

def calculate_llm_friendliness_score(llm_friendliness: Dict) -> int:
    """è¨ˆç®— LLM å‹å–„åº¦è©•åˆ†"""
    score = 0
    score += len(llm_friendliness.get("schema_detected", [])) * 10
    if llm_friendliness.get("content_readability") == "good":
        score += 40
    elif llm_friendliness.get("content_readability") == "fair":
        score += 20
    score += min(llm_friendliness.get("structured_data_score", 0) * 5, 30)
    return min(score, 100)

def display_root_files_analysis(root_files: Dict):
    """é¡¯ç¤ºæ ¹æª”æ¡ˆåˆ†æçµæœ"""
    st.subheader("ğŸ“ æ ¹æª”æ¡ˆåˆ†æ")
    
    # robots.txt
    if root_files.get("has_robots_txt"):
        st.success("âœ… robots.txt å­˜åœ¨")
        if root_files.get("robots_allows_ai_bots"):
            st.success("âœ… å…è¨± AI bots å­˜å–")
        else:
            st.warning("âš ï¸ å°é–äº†æŸäº› AI bots")
    else:
        st.error("âŒ robots.txt ä¸å­˜åœ¨")
    
    # sitemap.xml
    if root_files.get("has_sitemap_xml"):
        st.success("âœ… sitemap.xml å­˜åœ¨")
        if root_files.get("sitemap_is_valid"):
            st.success("âœ… sitemap.xml æ ¼å¼æ­£ç¢º")
        else:
            st.warning("âš ï¸ sitemap.xml æ ¼å¼å¯èƒ½æœ‰å•é¡Œ")
    else:
        st.error("âŒ sitemap.xml ä¸å­˜åœ¨")
    
    # llms.txt
    if root_files.get("has_llms_txt"):
        st.success("âœ… llms.txt å­˜åœ¨ (å‰ç»æ€§æŒ‡æ¨™)")
        st.text_area("llms.txt å…§å®¹", root_files.get("llms_txt_content", ""), height=100)
    else:
        st.info("â„¹ï¸ llms.txt ä¸å­˜åœ¨ (é€™æ˜¯æ­£å¸¸çš„ï¼Œç›®å‰ä»æ˜¯æ–°èˆˆæ¨™æº–)")

def display_architecture_analysis(architecture: Dict):
    """é¡¯ç¤ºæ¶æ§‹åˆ†æçµæœ"""
    st.subheader("ğŸ—ï¸ æ¶æ§‹åˆ†æ")
    
    # HTTPS
    if architecture.get("uses_https"):
        st.success("âœ… ä½¿ç”¨ HTTPS")
    else:
        st.error("âŒ æœªä½¿ç”¨ HTTPS")
    
    # å…§éƒ¨é€£çµçµæ§‹
    link_structure = architecture.get("internal_link_structure", "unknown")
    if link_structure == "good":
        st.success("âœ… å…§éƒ¨é€£çµçµæ§‹è‰¯å¥½")
    elif link_structure == "fair":
        st.info("â„¹ï¸ å…§éƒ¨é€£çµçµæ§‹ä¸€èˆ¬")
    else:
        st.warning("âš ï¸ å…§éƒ¨é€£çµçµæ§‹è¼ƒå·®")
    
    # å¤–éƒ¨é€£çµ
    external_links = architecture.get("external_links_count", 0)
    st.metric("å¤–éƒ¨é€£çµæ•¸é‡", external_links)

def display_llm_friendliness_analysis(llm_friendliness: Dict):
    """é¡¯ç¤º LLM å‹å–„åº¦åˆ†æçµæœ"""
    st.subheader("ğŸ¤– LLM å‹å–„åº¦åˆ†æ")
    
    # çµæ§‹åŒ–è³‡æ–™
    schema_types = llm_friendliness.get("schema_detected", [])
    if schema_types:
        st.success(f"âœ… ç™¼ç¾çµæ§‹åŒ–è³‡æ–™: {', '.join(schema_types)}")
    else:
        st.warning("âš ï¸ æœªç™¼ç¾çµæ§‹åŒ–è³‡æ–™")
    
    # å…§å®¹å¯è®€æ€§
    readability = llm_friendliness.get("content_readability", "unknown")
    if readability == "good":
        st.success("âœ… å…§å®¹çµæ§‹è‰¯å¥½")
    elif readability == "fair":
        st.info("â„¹ï¸ å…§å®¹çµæ§‹ä¸€èˆ¬")
    else:
        st.warning("âš ï¸ å…§å®¹çµæ§‹è¼ƒå·®")
    
    # PageSpeed åˆ†æ•¸
    pagespeed = llm_friendliness.get("pagespeed_scores", {})
    if pagespeed:
        col1, col2 = st.columns(2)
        with col1:
            mobile_perf = pagespeed.get("mobile", {}).get("performance", 0)
            st.metric("Mobile Performance", f"{mobile_perf}/100")
        with col2:
            desktop_perf = pagespeed.get("desktop", {}).get("performance", 0)
            st.metric("Desktop Performance", f"{desktop_perf}/100")

def display_recommendations(recommendations: List[Dict]):
    """é¡¯ç¤ºæ”¹å–„å»ºè­°"""
    st.subheader("ğŸ’¡ æ”¹å–„å»ºè­°")
    
    if not recommendations:
        st.info("ğŸ‰ æ²’æœ‰ç™¼ç¾éœ€è¦æ”¹å–„çš„å•é¡Œï¼")
        return
    
    for i, rec in enumerate(recommendations, 1):
        priority_color = {
            "High": "ğŸ”´",
            "Medium": "ğŸŸ¡",
            "Low": "ğŸŸ¢"
        }.get(rec.get("priority", "Medium"), "ğŸŸ¡")
        
        st.markdown(f"""
        ### {priority_color} {rec.get("issue", "Unknown Issue")}
        **å»ºè­°**: {rec.get("recommendation", "No recommendation")}
        **å„ªå…ˆç´š**: {rec.get("priority", "Medium")}
        **é¡åˆ¥**: {rec.get("category", "General")}
        """)

def display_ai_leader_analysis(ai_leader: Dict):
    """é¡¯ç¤º AI é ˜å°è€…åˆ†æ"""
    st.subheader("ğŸ¤– AI é ˜å°è€…åˆ†æ")
    
    # AI é ˜å°è€…åˆ†æ•¸
    ai_score = ai_leader.get("ai_leader_score", 0)
    st.metric("AI é ˜å°è€…åˆ†æ•¸", f"{ai_score}/100")
    
    # AI æŠ€è¡“æŒ‡æ¨™
    tech_indicators = ai_leader.get("ai_technology_indicators", [])
    if tech_indicators:
        st.success(f"âœ… ç™¼ç¾ AI æŠ€è¡“æŒ‡æ¨™: {', '.join(tech_indicators)}")
    else:
        st.warning("âš ï¸ æœªç™¼ç¾ AI æŠ€è¡“æŒ‡æ¨™")
    
    # AI å…§å®¹ä¿¡è™Ÿ
    content_signals = ai_leader.get("ai_content_signals", [])
    if content_signals:
        st.success(f"âœ… ç™¼ç¾ AI å…§å®¹ä¿¡è™Ÿ: {', '.join(content_signals)}")
    else:
        st.info("â„¹ï¸ æœªç™¼ç¾ AI ç›¸é—œå…§å®¹")
    
    # AI é ˜å°åœ°ä½
    position = ai_leader.get("ai_leadership_position", "unknown")
    position_emoji = {
        "leader": "ğŸ†",
        "emerging": "ğŸ“ˆ",
        "follower": "ğŸ“Š",
        "laggard": "âš ï¸"
    }.get(position, "â“")
    
    st.markdown(f"**AI é ˜å°åœ°ä½**: {position_emoji} {position.title()}")

def display_media_weights_analysis(media_weights: Dict):
    """é¡¯ç¤ºåª’é«”æ¬Šé‡åˆ†æ"""
    st.subheader("ğŸ“Š åª’é«”æ¬Šé‡åˆ†æ")
    
    # åª’é«”æåŠ
    mentions = media_weights.get("media_mentions", {})
    media_score = mentions.get("media_coverage_score", 0)
    st.metric("åª’é«”è¦†è“‹åˆ†æ•¸", f"{media_score:.1f}/100")
    
    recent_mentions = mentions.get("recent_mentions", [])
    if recent_mentions:
        st.markdown("### ğŸ“° æœ€è¿‘åª’é«”æåŠ")
        for mention in recent_mentions:
            sentiment_emoji = "âœ…" if mention.get("sentiment") == "positive" else "âš ï¸"
            st.markdown(f"""
            {sentiment_emoji} **{mention.get('source', 'Unknown')}** - {mention.get('date', 'Unknown')}
            {mention.get('title', 'No title')}
            """)
    
    # ç¤¾äº¤åª’é«”
    social = media_weights.get("social_media_presence", {})
    social_score = social.get("social_authority_score", 0)
    st.metric("ç¤¾äº¤åª’é«”æ¬Šå¨åˆ†æ•¸", f"{social_score:.1f}/100")
    
    platforms = social.get("platforms", [])
    if platforms:
        st.success(f"âœ… ç™¼ç¾ç¤¾äº¤åª’é«”å¹³å°: {', '.join(platforms)}")
    else:
        st.warning("âš ï¸ æœªç™¼ç¾ç¤¾äº¤åª’é«”é€£çµ")

def display_competitor_analysis(competitor_bench: Dict):
    """é¡¯ç¤ºç«¶çˆ­å°æ‰‹åˆ†æ"""
    st.subheader("ğŸ† ç«¶çˆ­å°æ‰‹åˆ†æ")
    
    # å¸‚å ´åœ°ä½
    market_position = competitor_bench.get("market_position", "unknown")
    position_emoji = {
        "leader": "ğŸ†",
        "strong": "ğŸ’ª",
        "average": "ğŸ“Š",
        "laggard": "âš ï¸"
    }.get(market_position, "â“")
    
    st.markdown(f"**å¸‚å ´åœ°ä½**: {position_emoji} {market_position.title()}")
    
    # ç«¶çˆ­å„ªå‹¢
    advantages = competitor_bench.get("competitive_advantages", [])
    if advantages:
        st.success("âœ… ç«¶çˆ­å„ªå‹¢:")
        for advantage in advantages:
            st.markdown(f"- {advantage}")
    
    # æ”¹å–„æ©Ÿæœƒ
    opportunities = competitor_bench.get("improvement_opportunities", [])
    if opportunities:
        st.warning("âš ï¸ æ”¹å–„æ©Ÿæœƒ:")
        for opportunity in opportunities:
            st.markdown(f"- {opportunity}")

def display_trend_analysis(trend_analysis: Dict):
    """é¡¯ç¤ºè¶¨å‹¢åˆ†æ"""
    st.subheader("ğŸ“ˆ è¶¨å‹¢åˆ†æ")
    
    # ç•¶å‰è¶¨å‹¢
    current_trends = trend_analysis.get("current_trends", [])
    if current_trends:
        st.markdown("### ğŸ”¥ ç•¶å‰è¶¨å‹¢")
        for trend in current_trends:
            st.markdown(f"- {trend}")
    
    # é æ¸¬æˆé•·
    predictions = trend_analysis.get("predicted_growth", {})
    if predictions:
        st.markdown("### ğŸ“Š é æ¸¬æˆé•·")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("AI æ¡ç”¨ç‡", f"{predictions.get('ai_adoption_rate', 0):.1f}%")
            st.metric("å…§å®¹æ¶ˆè²»æˆé•·", f"{predictions.get('content_consumption_growth', 0):.1f}%")
        with col2:
            st.metric("ç¤¾äº¤åƒèˆ‡åº¦å¢åŠ ", f"{predictions.get('social_engagement_increase', 0):.1f}%")
            st.metric("å¸‚å ´ä»½é¡æˆé•·", f"{predictions.get('market_share_growth', 0):.1f}%")

def display_strategic_recommendations(recommendations: List[Dict]):
    """é¡¯ç¤ºç­–ç•¥å»ºè­°"""
    st.subheader("ğŸ’¡ ç­–ç•¥å»ºè­°")
    
    if not recommendations:
        st.info("ğŸ‰ æ²’æœ‰ç­–ç•¥å»ºè­°")
        return
    
    for i, rec in enumerate(recommendations, 1):
        priority_color = {
            "High": "ğŸ”´",
            "Medium": "ğŸŸ¡",
            "Low": "ğŸŸ¢"
        }.get(rec.get("priority", "Medium"), "ğŸŸ¡")
        
        st.markdown(f"""
        ### {priority_color} {rec.get("strategy", "Unknown Strategy")}
        **æè¿°**: {rec.get("description", "No description")}
        **å„ªå…ˆç´š**: {rec.get("priority", "Medium")}
        **æ™‚é–“ç·š**: {rec.get("timeline", "Unknown")}
        **é æœŸå½±éŸ¿**: {rec.get("expected_impact", "Unknown")}
        
        **å¯¦æ–½æ­¥é©Ÿ**:
        """)
        
        steps = rec.get("implementation_steps", [])
        for step in steps:
            st.markdown(f"- {step}")

def display_eeat_detailed_results(result: Dict):
    """é¡¯ç¤ºè©³ç´° E-E-A-T çµæœ"""
    # é€™è£¡å¯ä»¥æ·»åŠ æ›´è©³ç´°çš„ E-E-A-T çµæœé¡¯ç¤º
    st.json(result)

def save_analysis_result(module: str, website: str, result: Dict):
    """å„²å­˜åˆ†æçµæœ"""
    # é€™è£¡å¯ä»¥å¯¦ç¾çµæœå„²å­˜é‚è¼¯
    pass

def load_analysis_reports():
    """è¼‰å…¥åˆ†æå ±å‘Š"""
    # é€™è£¡å¯ä»¥å¯¦ç¾å ±å‘Šè¼‰å…¥é‚è¼¯
    return []

if __name__ == "__main__":
    main() 