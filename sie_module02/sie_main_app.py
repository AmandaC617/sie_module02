import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime
import os
from typing import Dict, List, Optional

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from website_ai_readiness import run_website_analysis
from eeat_benchmarking import run_eeat_benchmarking
from eeat_module import run_module_2 as run_eeat_analysis

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="SIE å¹³å° - æ™ºèƒ½æœå°‹å¼•æ“å„ªåŒ–åˆ†æ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    .success-card {
        border-left-color: #28a745;
    }
    .warning-card {
        border-left-color: #ffc107;
    }
    .error-card {
        border-left-color: #dc3545;
    }
    .info-card {
        border-left-color: #17a2b8;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """ä¸»æ‡‰ç”¨ç¨‹å¼"""
    
    # å´é‚Šæ¬„é…ç½®
    with st.sidebar:
        st.title("ğŸš€ SIE å¹³å°")
        st.markdown("---")
        
        # API é‡‘é‘°è¨­å®š
        gemini_api_key = st.text_input(
            "ğŸ”‘ Gemini API é‡‘é‘°",
            type="password",
            help="è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ä»¥å•Ÿç”¨ AI å»ºè­°åŠŸèƒ½"
        )
        
        st.markdown("---")
        
        # é é¢é¸æ“‡
        page = st.selectbox(
            "ğŸ“„ é¸æ“‡åˆ†ææ¨¡çµ„",
            [
                "ğŸ  é¦–é ",
                "ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ",
                "ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ",
                "ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ",
                "ğŸ“ˆ åˆ†æå ±å‘Š"
            ]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ ä½¿ç”¨èªªæ˜")
        st.markdown("""
        1. **æ¨¡çµ„ 1**: åˆ†æç¶²ç«™æŠ€è¡“å¥åº·åº¦èˆ‡ AI å°±ç·’åº¦
        2. **æ¨¡çµ„ 2**: å‹•æ…‹ E-E-A-T è©•ä¼°èˆ‡ç«¶çˆ­åŸºæº–åˆ†æ
        3. **å®Œæ•´åˆ†æ**: å‚³çµ± E-E-A-T åˆ†æ
        4. **å ±å‘Š**: æŸ¥çœ‹æ­·å²åˆ†æçµæœ
        """)
    
    # ä¸»å…§å®¹å€åŸŸ
    if page == "ğŸ  é¦–é ":
        show_homepage()
    elif page == "ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ":
        show_module1_page(gemini_api_key)
    elif page == "ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ":
        show_module2_page(gemini_api_key)
    elif page == "ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ":
        show_full_eeat_page(gemini_api_key)
    elif page == "ğŸ“ˆ åˆ†æå ±å‘Š":
        show_reports_page()

def show_homepage():
    """é¡¯ç¤ºé¦–é """
    st.markdown('<div class="main-header">', unsafe_allow_html=True)
    st.title("ğŸš€ SIE å¹³å°")
    st.markdown("#### æ™ºèƒ½æœå°‹å¼•æ“å„ªåŒ–åˆ†æç³»çµ±")
    st.markdown("</div>", unsafe_allow_html=True)
    
    # åŠŸèƒ½ä»‹ç´¹
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ")
        st.markdown("""
        - âœ… robots.txt èˆ‡ LLM éµå¾æ€§æª¢æŸ¥
        - âœ… sitemap.xml é©—è­‰
        - âœ… llms.txt å‰ç»æ€§æŒ‡æ¨™
        - âœ… HTTPS å®‰å…¨æ€§æª¢æŸ¥
        - âœ… å…§éƒ¨é€£çµçµæ§‹åˆ†æ
        - âœ… Schema.org çµæ§‹åŒ–è³‡æ–™æª¢æ¸¬
        - âœ… å…§å®¹å¯è®€æ€§è©•ä¼°
        - âœ… AI æŠ€è¡“å»ºè­°ç”Ÿæˆ
        """)
    
    with col2:
        st.markdown("### ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ")
        st.markdown("""
        - ğŸ¤– AI é ˜å°è€…è­˜åˆ¥èˆ‡åˆ†æ
        - ğŸ“Š å‹•æ…‹åª’é«”æ¬Šé‡è©•ä¼°
        - ğŸ† ç«¶çˆ­å°æ‰‹åŸºæº–åˆ†æ
        - ğŸ“ˆ è¶¨å‹¢è¿½è¹¤èˆ‡é æ¸¬
        - ğŸ¯ ç­–ç•¥å»ºè­°ç”Ÿæˆ
        - ğŸ“± ç¤¾äº¤åª’é«”æ¬Šå¨åˆ†æ
        - ğŸ“° åª’é«”æåŠç›£æ§
        - ğŸ”„ å¸‚å ´æ©Ÿæœƒè­˜åˆ¥
        """)
    
    st.markdown("---")
    
    # çµ±è¨ˆè³‡è¨Š
    st.markdown("### ğŸ“Š å¹³å°çµ±è¨ˆ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("åˆ†ææ¬¡æ•¸", "1,234", "+12%")
    
    with col2:
        st.metric("ç¶²ç«™åˆ†æ", "567", "+8%")
    
    with col3:
        st.metric("ç«¶çˆ­å°æ‰‹", "89", "+15%")
    
    with col4:
        st.metric("å»ºè­°ç”Ÿæˆ", "2,345", "+20%")

def show_module1_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºæ¨¡çµ„ 1 é é¢"""
    st.title("ğŸ”§ æ¨¡çµ„ 1: ç¶²ç«™ AI å°±ç·’åº¦åˆ†æ")
    st.markdown("åˆ†æç¶²ç«™çš„æŠ€è¡“å¥åº·åº¦èˆ‡ AI å°±ç·’åº¦")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("module1_form"):
        website_url = st.text_input(
            "ğŸŒ ç¶²ç«™ URL",
            placeholder="ä¾‹å¦‚: example.com æˆ– https://example.com",
            help="è¼¸å…¥è¦åˆ†æçš„ç¶²ç«™ URL"
        )
        
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and website_url:
        with st.spinner("ğŸ” æ­£åœ¨åˆ†æç¶²ç«™ AI å°±ç·’åº¦..."):
            try:
                # åŸ·è¡Œåˆ†æ
                result = run_website_analysis(website_url, gemini_api_key)
                
                if "error" in result:
                    st.error(f"åˆ†æå¤±æ•—: {result['error']}")
                    return
                
                analysis_data = result.get("technical_seo_ai_readiness", {})
                
                # é¡¯ç¤ºåˆ†æçµæœ
                display_module1_results(analysis_data, website_url)
                
                # å„²å­˜çµæœ
                save_analysis_result("module1", website_url, result)
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def display_module1_results(analysis_data: Dict, website_url: str):
    """é¡¯ç¤ºæ¨¡çµ„ 1 åˆ†æçµæœ"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {website_url}")
    
    # ç¸½é«”è©•åˆ†
    col1, col2, col3 = st.columns(3)
    
    with col1:
        root_files = analysis_data.get("root_files", {})
        root_score = calculate_root_files_score(root_files)
        st.metric("æ ¹æª”æ¡ˆè©•åˆ†", f"{root_score}/100", "âœ…")
    
    with col2:
        architecture = analysis_data.get("architecture_signals", {})
        arch_score = calculate_architecture_score(architecture)
        st.metric("æ¶æ§‹è©•åˆ†", f"{arch_score}/100", "ğŸ—ï¸")
    
    with col3:
        llm_friendliness = analysis_data.get("llm_friendliness", {})
        llm_score = calculate_llm_friendliness_score(llm_friendliness)
        st.metric("LLM å‹å–„åº¦", f"{llm_score}/100", "ğŸ¤–")
    
    st.markdown("---")
    
    # è©³ç´°åˆ†æçµæœ
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“ æ ¹æª”æ¡ˆ", "ğŸ—ï¸ æ¶æ§‹", "ğŸ¤– LLM å‹å–„åº¦", "ğŸ’¡ å»ºè­°", "ğŸ“ ç”¨æˆ¶è©•è«–åˆ†æ", "ğŸ§­ å…§å®¹èˆ‡æ¶ˆè²»è€…æ—…ç¨‹å°æ‡‰"])
    
    with tab1:
        display_root_files_analysis(analysis_data.get("root_files", {}))
    
    with tab2:
        display_architecture_analysis(analysis_data.get("architecture_signals", {}))
    
    with tab3:
        display_llm_friendliness_analysis(analysis_data.get("llm_friendliness", {}))
    
    with tab4:
        display_recommendations(analysis_data.get("actionable_recommendations", []))
    
    with tab5:
        review = analysis_data.get('user_review_analysis', {})
        st.subheader('ç”¨æˆ¶è©•è«–åˆ†æ')
        st.write(f"è©•è«–ç¸½æ•¸: {review.get('review_count', 0)}")
        st.write(f"å¹³å‡åˆ†æ•¸: {review.get('average_rating')}")
        st.write(f"æƒ…æ„Ÿåˆ†å¸ƒ: {review.get('sentiment_summary')}")
        for r in review.get('review_samples', []):
            st.markdown(f"- ç¬¬{r.get('page', 1)}é  | {r.get('sentiment', '')} | {r.get('author', 'åŒ¿å')}: {r.get('text')}")
    
    with tab6:
        faq_journey = analysis_data.get('faq_journey_analysis', {})
        st.subheader('ç¶²ç«™å…§å®¹èˆ‡æ¶ˆè²»è€…æ—…ç¨‹å°æ‡‰åˆ†æ')
        faqs = faq_journey.get('faqs', [])
        if not faqs:
            st.info('å°šæœªç”¢ç”Ÿ FAQ æˆ–ç¼ºå°‘å“é¡/å“ç‰Œ/å¸‚å ´è³‡è¨Š')
        else:
            for f in faqs:
                covered = 'âœ… è¦†è“‹' if f.get('covered') else 'âŒ æœªè¦†è“‹'
                authority = 'ï¼ˆå…·æ¬Šå¨æ€§ï¼‰' if f.get('authority') else ''
                st.markdown(f"- **{f['question_zh']}** / {f['question_en']}<br>\n  {covered} {authority} æ–¼ {f.get('location', '')}", unsafe_allow_html=True)
            # å»ºè­°
            not_covered = [f for f in faqs if not f.get('covered')]
            if not_covered:
                st.warning('éƒ¨åˆ†å¸¸è¦‹æ¶ˆè²»è€…å•é¡Œæœªè¢«è¦†è“‹ï¼Œå»ºè­°ï¼š')
                for f in not_covered:
                    st.markdown(f"- è«‹è£œå……ï¼š{f['question_zh']} / {f['question_en']}")
            else:
                st.success('æ‰€æœ‰é—œéµæ¶ˆè²»è€…å•é¡Œçš†æœ‰è¦†è“‹ï¼Œå…§å®¹å®Œæ•´ï¼')

def show_module2_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºæ¨¡çµ„ 2 é é¢"""
    st.title("ğŸ“Š æ¨¡çµ„ 2: E-E-A-T åŸºæº–åˆ†æ")
    st.markdown("å‹•æ…‹ E-E-A-T è©•ä¼°èˆ‡ç«¶çˆ­åŸºæº–åˆ†æ")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("module2_form"):
        markets = st.multiselect(
            "ğŸŒ å¸‚å ´ï¼ˆå¯å¤šé¸ï¼‰",
            ["å°ç£", "ä¸­åœ‹", "ç¾åœ‹", "å…¨çƒ", "å…¶ä»–"],
            default=["å°ç£"],
            help="å¯åŒæ™‚åˆ†æå¤šå€‹å¸‚å ´"
        )
        if "å…¶ä»–" in markets:
            custom_market = st.text_input("è«‹è¼¸å…¥è‡ªè¨‚å¸‚å ´åç¨±", "")
            if custom_market:
                markets = [m for m in markets if m != "å…¶ä»–"] + [custom_market]
        industry = st.selectbox(
            "ğŸ­ è¡Œæ¥­",
            ["å®¶é›»", "é›»å­", "æ±½è»Š", "é£Ÿå“", "é‡‘è", "é†«ç™‚", "å…¶ä»–"],
            index=0,
            help="é¸æ“‡è¦åˆ†æçš„è¡Œæ¥­"
        )
        if industry == "å…¶ä»–":
            industry = st.text_input("è«‹è¼¸å…¥è‡ªè¨‚è¡Œæ¥­åç¨±", "")
        brand = st.text_input(
            "ğŸ¢ å“ç‰Œ",
            placeholder="ä¾‹å¦‚: ExampleBrand",
            help="è¼¸å…¥å“ç‰Œåç¨±"
        )
        product = st.text_input(
            "ğŸ“¦ ç”¢å“/å“é¡",
            placeholder="ä¾‹å¦‚: ç©ºæ°£æ¸…æ·¨æ©Ÿ",
            help="è¼¸å…¥ç”¢å“æˆ–å“é¡åç¨±"
        )
        official_site = st.text_input(
            "ğŸŒ å®˜ç¶²é€£çµ",
            placeholder="ä¾‹å¦‚: https://brand.com",
            help="è¼¸å…¥å“ç‰Œæˆ–ç”¢å“å®˜ç¶²ç¶²å€"
        )
        competitors = st.text_area(
            "ğŸ† ç«¶çˆ­å°æ‰‹ (æ¯è¡Œä¸€å€‹)",
            placeholder="competitor1.com\ncompetitor2.com\ncompetitor3.com",
            help="è¼¸å…¥ç«¶çˆ­å°æ‰‹ç¶²ç«™ï¼Œæ¯è¡Œä¸€å€‹"
        )
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and official_site and markets:
        competitor_list = []
        if competitors:
            competitor_list = [comp.strip() for comp in competitors.split('\n') if comp.strip()]
        all_results = {}
        with st.spinner("ğŸ” æ­£åœ¨åŸ·è¡Œå¤šå¸‚å ´ E-E-A-T åŸºæº–åˆ†æ..."):
            for market in markets:
                try:
                    result = run_eeat_benchmarking(
                        official_site, competitor_list, gemini_api_key, market, product, brand
                    )
                    all_results[market] = result.get("eeat_benchmarking", {})
                except Exception as e:
                    all_results[market] = {"error": str(e)}
        # è·¨å¸‚å ´æŒ‡æ¨™ç¸½è¦½è¡¨
        if len(all_results) > 1:
            overview = []
            for market, data in all_results.items():
                if "error" in data:
                    overview.append({
                        "å¸‚å ´": market,
                        "å·®è·åˆ†æ•¸": "-",
                        "åª’é«”åˆ†æ•¸": "-",
                        "ç¤¾ç¾¤åˆ†æ•¸": "-",
                        "é ˜å°è€…": "-"
                    })
                else:
                    gap = data.get("brand_gap_analysis", {})
                    media_weights = data.get("dynamic_media_weights", {})
                    media_score = media_weights.get("media_mentions", {}).get("media_coverage_score", "-")
                    social_score = media_weights.get("social_media_presence", {}).get("social_authority_score", "-")
                    leaders = data.get("leaders_recommendation", [])
                    leader_names = ", ".join([l.get("name", "") for l in leaders]) if leaders else "-"
                    overview.append({
                        "å¸‚å ´": market,
                        "å·®è·åˆ†æ•¸": gap.get("gap_score", "-"),
                        "åª’é«”åˆ†æ•¸": media_score,
                        "ç¤¾ç¾¤åˆ†æ•¸": social_score,
                        "é ˜å°è€…": leader_names
                    })
            df = pd.DataFrame(overview)
            st.markdown("### ğŸŒ è·¨å¸‚å ´æŒ‡æ¨™ç¸½è¦½")
            st.dataframe(df, use_container_width=True)
        # é¡¯ç¤ºå¤šå¸‚å ´åˆ†æçµæœ
        tabs = st.tabs([f"{m} å¸‚å ´" for m in all_results])
        for i, market in enumerate(all_results):
            with tabs[i]:
                if "error" in all_results[market]:
                    st.error(f"{market} åˆ†æå¤±æ•—: {all_results[market]['error']}")
                else:
                    display_module2_results(all_results[market], official_site, market, industry, product, brand)
        # å„²å­˜çµæœï¼ˆåƒ…å­˜ç¬¬ä¸€å€‹å¸‚å ´çµæœï¼‰
        save_analysis_result("module2", official_site, {m: all_results[m] for m in all_results})

def display_module2_results(analysis_data: Dict, official_site: str, market: str, industry: str, product: str, brand: str):
    """é¡¯ç¤ºæ¨¡çµ„ 2 åˆ†æçµæœï¼ˆä»¥å¸‚å ´ç‚ºä¸»åˆ†çµ„ï¼‰"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {market}ï½œ{industry}ï½œ{brand}ï½œ{product}")
    st.markdown(f"[å®˜ç¶²é€£çµ]({official_site})")
    # é ˜å°è€…æ¯”å°å€å¡Š
    leaders = analysis_data.get("leaders_recommendation", [])
    st.subheader(f"ğŸ† {market}ï½œ{industry}ï½œ{product}ï½œ{brand} é ˜å°è€…æ¯”å°")
    if not leaders:
        st.info("å°šç„¡ LLM æ¨è–¦é ˜å°è€…è³‡æ–™")
    else:
        for leader in leaders:
            star = "â­" if leader.get("is_benchmark") else ""
            st.markdown(f"- [{leader['name']}]({leader['website']}) {star}<br>æ¨è–¦èªªæ˜ï¼š{leader['reason']}", unsafe_allow_html=True)
    st.markdown("---")
    # å“ç‰Œèˆ‡æ¨™ç«¿å·®ç•°åˆ†æå€å¡Š
    gap = analysis_data.get("brand_gap_analysis", {})
    st.subheader(f"ğŸ“‰ {market}ï½œ{brand} èˆ‡æ¨™ç«¿å·®ç•°åˆ†æ")
    if not gap or not isinstance(gap, dict) or "summary" not in gap:
        st.info("å°šç„¡ LLM å·®ç•°åˆ†æè³‡æ–™")
    else:
        st.markdown(f"**æ•´é«”å·®è·åˆ†æ•¸**ï¼š{gap.get('gap_score', 'N/A')}/100")
        st.markdown(f"**å„ªå‹¢**ï¼š")
        for adv in gap.get("advantages", []):
            st.markdown(f"- {adv}")
        st.markdown(f"**åŠ£å‹¢**ï¼š")
        for disadv in gap.get("disadvantages", []):
            st.markdown(f"- {disadv}")
        st.markdown(f"**å»ºè­°**ï¼š")
        for rec in gap.get("recommendations", []):
            st.markdown(f"- {rec}")
        st.markdown(f"**ç¸½çµ**ï¼š{gap.get('summary', '')}")
    st.markdown("---")
    # ç¸½é«”è©•åˆ†ï¼ˆç§»é™¤AIé ˜å°è€…åˆ†æ•¸ï¼‰
    cols = st.columns(3)
    with cols[0]:
        media_weights = analysis_data.get("dynamic_media_weights", {})
        social_score = media_weights.get("social_media_presence", {})
        social_score = social_score.get("social_authority_score", 0)
        st.metric("ç¤¾äº¤åª’é«”æ¬Šå¨", f"{social_score:.1f}/100", "ğŸ“±")
    with cols[1]:
        competitor_bench = analysis_data.get("competitor_benchmarking", {})
        market_position = competitor_bench.get("market_position", "unknown")
        st.metric(f"{market} å¸‚å ´åœ°ä½", str(market_position).title())
    with cols[2]:
        media_weights = analysis_data.get("dynamic_media_weights", {})
        media_score = media_weights.get("media_coverage_score", 0)
        st.metric("åª’é«”æ¬Šé‡åˆ†æ•¸", f"{media_score}/100", "ğŸ“°")
    st.markdown("---")
    # åª’é«”æ¬Šé‡åˆ†æå€å¡Š
    media_weights = analysis_data.get("dynamic_media_weights", {})
    st.subheader("ğŸ“Š åª’é«”æ¬Šé‡åˆ†æ")
    st.markdown(f"**åª’é«”æ¬Šé‡åˆ†æ•¸**ï¼š{media_weights.get('media_coverage_score', 0)}/100")
    st.markdown(f"**è¦†è“‹ç‡**ï¼š{media_weights.get('coverage_rate', 0):.0%}ï¼ˆ{media_weights.get('covered_count', 0)}/{media_weights.get('total_count', 0)}ï¼‰")
    sources = media_weights.get("sources", {})
    # ä¾†æºæ¸…å–®è¡¨æ ¼
    for media_type in ["æ–°è", "ç¤¾ç¾¤", "è«–å£‡", "å½±éŸ³", "Wiki"]:
        items = sources.get(media_type, [])
        if not items:
            continue
        st.markdown(f"#### {media_type}")
        df = pd.DataFrame([
            {
                "ä¾†æºåç¨±": src.get('name', ''),
                "ä¿¡ä»»åº¦": src.get('trust_score', 0),
                "é«˜æ¬Šå¨": 'â­' if src.get('llm_favorite') else '',
                "è¦†è“‹": 'âœ…' if src.get('covered') else 'âŒ',
                "æ¨è«–åˆ†æ•¸": src.get('llm_score', '') if media_type != "æ–°è" else '',
                "æ¨è«–ä¾æ“š": src.get('llm_reason', '') if media_type != "æ–°è" else '',
                "æ’åºä¾æ“š": src.get('reason', '')
            }
            for src in items
        ])
        st.dataframe(df, use_container_width=True)
    # åª’é«”æ¬Šé‡åˆ†æ•¸é•·æ¢åœ–
    bar_data = []
    for media_type in ["æ–°è", "ç¤¾ç¾¤", "è«–å£‡", "å½±éŸ³", "Wiki"]:
        items = sources.get(media_type, [])
        for src in items:
            bar_data.append({
                "ä¾†æº": src.get('name', ''),
                "é¡å‹": media_type,
                "ä¿¡ä»»åº¦": src.get('trust_score', 0),
                "è¦†è“‹": 1 if src.get('covered') else 0
            })
    if bar_data:
        bar_df = pd.DataFrame(bar_data)
        fig = go.Figure()
        for t in bar_df['é¡å‹'].unique():
            sub = bar_df[bar_df['é¡å‹'] == t]
            fig.add_trace(go.Bar(
                x=sub['ä¾†æº'],
                y=sub['ä¿¡ä»»åº¦'],
                name=t,
                marker_color=None
            ))
        fig.update_layout(barmode='group', title='ä¾†æºä¿¡ä»»åº¦é•·æ¢åœ–', xaxis_title='ä¾†æº', yaxis_title='ä¿¡ä»»åº¦')
        st.plotly_chart(fig, use_container_width=True)
    # å„é¡å‹è¦†è“‹ç‡é›·é”åœ–
    radar_labels = []
    radar_values = []
    for media_type in ["æ–°è", "ç¤¾ç¾¤", "è«–å£‡", "å½±éŸ³", "Wiki"]:
        items = sources.get(media_type, [])
        if items:
            radar_labels.append(media_type)
            radar_values.append(sum(1 for src in items if src.get('covered')) / len(items))
    if radar_labels:
        radar_fig = go.Figure()
        radar_fig.add_trace(go.Scatterpolar(r=radar_values, theta=radar_labels, fill='toself', name='è¦†è“‹ç‡'))
        radar_fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,1])), showlegend=False, title='å„é¡å‹ä¾†æºè¦†è“‹ç‡é›·é”åœ–')
        st.plotly_chart(radar_fig, use_container_width=True)
    # åŒ¯å‡ºå…§å®¹è‡ªè¨‚å‹¾é¸
    st.markdown("---")
    export_options = st.multiselect(
        "é¸æ“‡è¦åŒ¯å‡ºçš„å…§å®¹å€å¡Š",
        ["ä¾†æºæ¸…å–®", "åª’é«”æ¬Šé‡åœ–è¡¨", "ç«¶çˆ­åˆ†æ", "å·®ç•°åˆ†æ", "ç­–ç•¥å»ºè­°"],
        default=["ä¾†æºæ¸…å–®", "åª’é«”æ¬Šé‡åœ–è¡¨"]
    )
    pdf_title = st.text_input("PDF å ±å‘Šæ¨™é¡Œ", f"{market}ï½œ{brand} åª’é«”æ¬Šé‡èˆ‡E-E-A-Tåˆ†æå ±å‘Š")
    # ç«¶çˆ­åˆ†æè¡¨æ ¼
    competitor_bench = analysis_data.get("competitor_benchmarking", {})
    if "ç«¶çˆ­åˆ†æ" in export_options:
        st.subheader("ğŸ† ç«¶çˆ­å°æ‰‹åŸºæº–åˆ†æ")
        comp_df = pd.DataFrame([
            {"ç«¶çˆ­å°æ‰‹": k, **v} for k, v in competitor_bench.get("competitors", {}).items()
        ]) if competitor_bench.get("competitors") else pd.DataFrame()
        if not comp_df.empty:
            st.dataframe(comp_df, use_container_width=True)
    # å·®ç•°åˆ†æè¡¨æ ¼
    gap = analysis_data.get("brand_gap_analysis", {})
    if "å·®ç•°åˆ†æ" in export_options:
        st.subheader("ğŸ“‰ å“ç‰Œèˆ‡æ¨™ç«¿å·®ç•°åˆ†æ")
        gap_df = pd.DataFrame({
            "å„ªå‹¢": gap.get("advantages", []),
            "åŠ£å‹¢": gap.get("disadvantages", []),
            "å»ºè­°": gap.get("recommendations", [])
        })
        st.dataframe(gap_df, use_container_width=True)
    # ç­–ç•¥å»ºè­°è¡¨æ ¼
    strategies = analysis_data.get("strategic_recommendations", [])
    if "ç­–ç•¥å»ºè­°" in export_options:
        st.subheader("ğŸ’¡ ç­–ç•¥å»ºè­°")
        strat_df = pd.DataFrame(strategies)
        if not strat_df.empty:
            st.dataframe(strat_df, use_container_width=True)
    # é€²éš PDF/Excel åŒ¯å‡º
    import io
    import base64
    export_sections = []
    if "ä¾†æºæ¸…å–®" in export_options:
        export_sections.append(("ä¾†æºæ¸…å–®", export_df))
    if "åª’é«”æ¬Šé‡åœ–è¡¨" in export_options and bar_data:
        export_sections.append(("åª’é«”æ¬Šé‡é•·æ¢åœ–", bar_df))
    if "ç«¶çˆ­åˆ†æ" in export_options and not comp_df.empty:
        export_sections.append(("ç«¶çˆ­åˆ†æ", comp_df))
    if "å·®ç•°åˆ†æ" in export_options:
        export_sections.append(("å·®ç•°åˆ†æ", gap_df))
    if "ç­–ç•¥å»ºè­°" in export_options and not strat_df.empty:
        export_sections.append(("ç­–ç•¥å»ºè­°", strat_df))
    # åŒ¯å‡º Excel
    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
        for title, df in export_sections:
            df.to_excel(writer, sheet_name=title[:31], index=False)
    st.download_button(
        label="è‡ªè¨‚å…§å®¹åŒ¯å‡º Excel",
        data=excel_buffer.getvalue(),
        file_name=f"{market}_{brand}_media_analysis_custom.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    # é€²éš PDF åŒ¯å‡º
    try:
        from fpdf import FPDF
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=14)
        pdf.cell(0, 12, pdf_title, ln=True, align='C')
        pdf.set_font("Arial", size=10)
        for title, df in export_sections:
            pdf.ln(8)
            pdf.set_font("Arial", style='B', size=12)
            pdf.cell(0, 10, title, ln=True)
            pdf.set_font("Arial", size=10)
            for i, row in df.iterrows():
                pdf.cell(0, 8, str(row.to_dict()), ln=True)
        pdf_buffer = io.BytesIO(pdf.output(dest='S').encode('latin1'))
        st.download_button(
            label="è‡ªè¨‚å…§å®¹åŒ¯å‡º PDF",
            data=pdf_buffer.getvalue(),
            file_name=f"{market}_{brand}_media_analysis_custom.pdf",
            mime="application/pdf"
        )
    except Exception:
        st.info("å¦‚éœ€ PDF åŒ¯å‡ºï¼Œè«‹å®‰è£ fpdf å¥—ä»¶ã€‚")
    # å…¶é¤˜åˆ†æå€å¡Šï¼ˆç§»é™¤AIé ˜å°è€…åˆ†ætabï¼‰
    tab1, tab2, tab3 = st.tabs([f"ğŸ† {market} ç«¶çˆ­åˆ†æ", "ğŸ“ˆ è¶¨å‹¢", "ğŸ’¡ ç­–ç•¥"])
    with tab1:
        display_competitor_analysis(analysis_data.get("competitor_benchmarking", {}))
    with tab2:
        display_trend_analysis(analysis_data.get("trend_analysis", {}))
    with tab3:
        display_strategic_recommendations(analysis_data.get("strategic_recommendations", []))

def show_full_eeat_page(gemini_api_key: Optional[str]):
    """é¡¯ç¤ºå®Œæ•´ E-E-A-T åˆ†æé é¢"""
    st.title("ğŸ¯ å®Œæ•´ E-E-A-T åˆ†æ")
    st.markdown("å‚³çµ± E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness) åˆ†æ")
    
    # è¼¸å…¥å€åŸŸ
    with st.form("full_eeat_form"):
        website_url = st.text_input(
            "ğŸŒ ç¶²ç«™ URL",
            placeholder="ä¾‹å¦‚: example.com",
            help="è¼¸å…¥è¦åˆ†æçš„ç¶²ç«™ URL"
        )
        
        company_name = st.text_input(
            "ğŸ¢ å…¬å¸åç¨±",
            placeholder="ä¾‹å¦‚: Example Corp",
            help="è¼¸å…¥å…¬å¸æˆ–çµ„ç¹”åç¨±"
        )
        
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")
    
    if submitted and website_url and company_name:
        with st.spinner("ğŸ” æ­£åœ¨åŸ·è¡Œå®Œæ•´ E-E-A-T åˆ†æ..."):
            try:
                # åŸ·è¡Œåˆ†æ
                result = run_eeat_analysis(website_url, company_name, gemini_api_key)
                
                if "error" in result:
                    st.error(f"åˆ†æå¤±æ•—: {result['error']}")
                    return
                
                # é¡¯ç¤ºåˆ†æçµæœ
                display_full_eeat_results(result, website_url, company_name)
                
                # å„²å­˜çµæœ
                save_analysis_result("full_eeat", website_url, result)
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

def display_full_eeat_results(result: Dict, website_url: str, company_name: str):
    """é¡¯ç¤ºå®Œæ•´ E-E-A-T åˆ†æçµæœ"""
    st.success(f"âœ… åˆ†æå®Œæˆ: {company_name} ({website_url})")
    
    # ç¸½é«” E-E-A-T åˆ†æ•¸
    eeat_scores = result.get("eeat_scores", {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        experience_score = eeat_scores.get("experience", 0)
        st.metric("Experience", f"{experience_score}/100", "ğŸ“š")
    
    with col2:
        expertise_score = eeat_scores.get("expertise", 0)
        st.metric("Expertise", f"{expertise_score}/100", "ğŸ“")
    
    with col3:
        authoritativeness_score = eeat_scores.get("authoritativeness", 0)
        st.metric("Authoritativeness", f"{authoritativeness_score}/100", "ğŸ†")
    
    with col4:
        trustworthiness_score = eeat_scores.get("trustworthiness", 0)
        st.metric("Trustworthiness", f"{trustworthiness_score}/100", "âœ…")
    
    # é¡¯ç¤ºè©³ç´°åˆ†æçµæœ
    display_eeat_detailed_results(result)

def show_reports_page():
    """é¡¯ç¤ºåˆ†æå ±å‘Šé é¢"""
    st.title("ğŸ“ˆ åˆ†æå ±å‘Š")
    st.markdown("æŸ¥çœ‹æ­·å²åˆ†æçµæœèˆ‡è¶¨å‹¢")
    
    # è¼‰å…¥æ­·å²å ±å‘Š
    reports = load_analysis_reports()
    
    if not reports:
        st.info("ğŸ“ å°šç„¡åˆ†æå ±å‘Šï¼Œè«‹å…ˆåŸ·è¡Œåˆ†æ")
        return
    
    # å ±å‘Šåˆ—è¡¨
    for report in reports:
        with st.expander(f"ğŸ“Š {report['timestamp']} - {report['website']} ({report['module']})"):
            st.json(report['result'])

# è¼”åŠ©å‡½æ•¸
def calculate_root_files_score(root_files: Dict) -> int:
    """è¨ˆç®—æ ¹æª”æ¡ˆè©•åˆ†"""
    score = 0
    if root_files.get("has_robots_txt"):
        score += 25
    if root_files.get("robots_allows_ai_bots"):
        score += 25
    if root_files.get("has_sitemap_xml"):
        score += 25
    if root_files.get("sitemap_is_valid"):
        score += 15
    if root_files.get("has_llms_txt"):
        score += 10
    return score

def calculate_architecture_score(architecture: Dict) -> int:
    """è¨ˆç®—æ¶æ§‹è©•åˆ†"""
    score = 0
    if architecture.get("uses_https"):
        score += 30
    if architecture.get("internal_link_structure") == "good":
        score += 40
    elif architecture.get("internal_link_structure") == "fair":
        score += 20
    score += min(architecture.get("estimated_authority_links", 0) * 2, 30)
    return score

def calculate_llm_friendliness_score(llm_friendliness: Dict) -> int:
    """è¨ˆç®— LLM å‹å–„åº¦è©•åˆ†"""
    score = 0
    score += len(llm_friendliness.get("schema_detected", [])) * 10
    if llm_friendliness.get("content_readability") == "good":
        score += 40
    elif llm_friendliness.get("content_readability") == "fair":
        score += 20
    score += min(llm_friendliness.get("structured_data_score", 0) * 5, 30)
    return min(score, 100)

def display_root_files_analysis(root_files: Dict):
    """é¡¯ç¤ºæ ¹æª”æ¡ˆåˆ†æçµæœ"""
    st.subheader("ğŸ“ æ ¹æª”æ¡ˆåˆ†æ")
    
    # robots.txt
    if root_files.get("has_robots_txt"):
        st.success("âœ… robots.txt å­˜åœ¨")
        if root_files.get("robots_allows_ai_bots"):
            st.success("âœ… å…è¨± AI bots å­˜å–")
        else:
            st.warning("âš ï¸ å°é–äº†æŸäº› AI bots")
    else:
        st.error("âŒ robots.txt ä¸å­˜åœ¨")
    
    # sitemap.xml
    if root_files.get("has_sitemap_xml"):
        st.success("âœ… sitemap.xml å­˜åœ¨")
        if root_files.get("sitemap_is_valid"):
            st.success("âœ… sitemap.xml æ ¼å¼æ­£ç¢º")
        else:
            st.warning("âš ï¸ sitemap.xml æ ¼å¼å¯èƒ½æœ‰å•é¡Œ")
    else:
        st.error("âŒ sitemap.xml ä¸å­˜åœ¨")
    
    # llms.txt
    if root_files.get("has_llms_txt"):
        st.success("âœ… llms.txt å­˜åœ¨ (å‰ç»æ€§æŒ‡æ¨™)")
        st.text_area("llms.txt å…§å®¹", root_files.get("llms_txt_content", ""), height=100)
    else:
        st.info("â„¹ï¸ llms.txt ä¸å­˜åœ¨ (é€™æ˜¯æ­£å¸¸çš„ï¼Œç›®å‰ä»æ˜¯æ–°èˆˆæ¨™æº–)")

def display_architecture_analysis(architecture: Dict):
    """é¡¯ç¤ºæ¶æ§‹åˆ†æçµæœ"""
    st.subheader("ğŸ—ï¸ æ¶æ§‹åˆ†æ")
    
    # HTTPS
    if architecture.get("uses_https"):
        st.success("âœ… ä½¿ç”¨ HTTPS")
    else:
        st.error("âŒ æœªä½¿ç”¨ HTTPS")
    
    # å…§éƒ¨é€£çµçµæ§‹
    link_structure = architecture.get("internal_link_structure", "unknown")
    if link_structure == "good":
        st.success("âœ… å…§éƒ¨é€£çµçµæ§‹è‰¯å¥½")
    elif link_structure == "fair":
        st.info("â„¹ï¸ å…§éƒ¨é€£çµçµæ§‹ä¸€èˆ¬")
    else:
        st.warning("âš ï¸ å…§éƒ¨é€£çµçµæ§‹è¼ƒå·®")
    
    # å¤–éƒ¨é€£çµ
    external_links = architecture.get("external_links_count", 0)
    st.metric("å¤–éƒ¨é€£çµæ•¸é‡", external_links)

def display_llm_friendliness_analysis(llm_friendliness: Dict):
    """é¡¯ç¤º LLM å‹å–„åº¦åˆ†æçµæœ"""
    st.subheader("ğŸ¤– LLM å‹å–„åº¦åˆ†æ")
    
    # çµæ§‹åŒ–è³‡æ–™
    schema_types = llm_friendliness.get("schema_detected", [])
    if schema_types:
        st.success(f"âœ… ç™¼ç¾çµæ§‹åŒ–è³‡æ–™: {', '.join(schema_types)}")
    else:
        st.warning("âš ï¸ æœªç™¼ç¾çµæ§‹åŒ–è³‡æ–™")
    
    # å…§å®¹å¯è®€æ€§
    readability = llm_friendliness.get("content_readability", "unknown")
    if readability == "good":
        st.success("âœ… å…§å®¹çµæ§‹è‰¯å¥½")
    elif readability == "fair":
        st.info("â„¹ï¸ å…§å®¹çµæ§‹ä¸€èˆ¬")
    else:
        st.warning("âš ï¸ å…§å®¹çµæ§‹è¼ƒå·®")
    
    # PageSpeed åˆ†æ•¸
    pagespeed = llm_friendliness.get("pagespeed_scores", {})
    if pagespeed:
        col1, col2 = st.columns(2)
        with col1:
            mobile_perf = pagespeed.get("mobile", {}).get("performance", 0)
            st.metric("Mobile Performance", f"{mobile_perf}/100")
        with col2:
            desktop_perf = pagespeed.get("desktop", {}).get("performance", 0)
            st.metric("Desktop Performance", f"{desktop_perf}/100")

def display_recommendations(recommendations: List[Dict]):
    """é¡¯ç¤ºæ”¹å–„å»ºè­°"""
    st.subheader("ğŸ’¡ æ”¹å–„å»ºè­°")
    
    if not recommendations:
        st.info("ğŸ‰ æ²’æœ‰ç™¼ç¾éœ€è¦æ”¹å–„çš„å•é¡Œï¼")
        return
    
    for i, rec in enumerate(recommendations, 1):
        priority_color = {
            "High": "ğŸ”´",
            "Medium": "ğŸŸ¡",
            "Low": "ğŸŸ¢"
        }.get(rec.get("priority", "Medium"), "ğŸŸ¡")
        
        st.markdown(f"""
        ### {priority_color} {rec.get("issue", "Unknown Issue")}
        **å»ºè­°**: {rec.get("recommendation", "No recommendation")}
        **å„ªå…ˆç´š**: {rec.get("priority", "Medium")}
        **é¡åˆ¥**: {rec.get("category", "General")}
        """)

def display_competitor_analysis(competitor_bench: Dict):
    """é¡¯ç¤ºç«¶çˆ­å°æ‰‹åˆ†æ"""
    st.subheader("ğŸ† ç«¶çˆ­å°æ‰‹åˆ†æ")
    
    # å¸‚å ´åœ°ä½
    market_position = competitor_bench.get("market_position", "unknown")
    position_emoji = {
        "leader": "ğŸ†",
        "strong": "ğŸ’ª",
        "average": "ğŸ“Š",
        "laggard": "âš ï¸"
    }.get(market_position, "â“")
    
    st.markdown(f"**å¸‚å ´åœ°ä½**: {position_emoji} {market_position.title()}")
    
    # ç«¶çˆ­å„ªå‹¢
    advantages = competitor_bench.get("competitive_advantages", [])
    if advantages:
        st.success("âœ… ç«¶çˆ­å„ªå‹¢:")
        for advantage in advantages:
            st.markdown(f"- {advantage}")
    
    # æ”¹å–„æ©Ÿæœƒ
    opportunities = competitor_bench.get("improvement_opportunities", [])
    if opportunities:
        st.warning("âš ï¸ æ”¹å–„æ©Ÿæœƒ:")
        for opportunity in opportunities:
            st.markdown(f"- {opportunity}")

def display_trend_analysis(trend_analysis: Dict):
    """é¡¯ç¤ºè¶¨å‹¢åˆ†æ"""
    st.subheader("ğŸ“ˆ è¶¨å‹¢åˆ†æ")
    
    # ç•¶å‰è¶¨å‹¢
    current_trends = trend_analysis.get("current_trends", [])
    if current_trends:
        st.markdown("### ğŸ”¥ ç•¶å‰è¶¨å‹¢")
        for trend in current_trends:
            st.markdown(f"- {trend}")
    
    # é æ¸¬æˆé•·
    predictions = trend_analysis.get("predicted_growth", {})
    if predictions:
        st.markdown("### ğŸ“Š é æ¸¬æˆé•·")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("AI æ¡ç”¨ç‡", f"{predictions.get('ai_adoption_rate', 0):.1f}%")
            st.metric("å…§å®¹æ¶ˆè²»æˆé•·", f"{predictions.get('content_consumption_growth', 0):.1f}%")
        with col2:
            st.metric("ç¤¾äº¤åƒèˆ‡åº¦å¢åŠ ", f"{predictions.get('social_engagement_increase', 0):.1f}%")
            st.metric("å¸‚å ´ä»½é¡æˆé•·", f"{predictions.get('market_share_growth', 0):.1f}%")

def display_strategic_recommendations(recommendations: List[Dict]):
    """é¡¯ç¤ºç­–ç•¥å»ºè­°"""
    st.subheader("ğŸ’¡ ç­–ç•¥å»ºè­°")
    
    if not recommendations:
        st.info("ğŸ‰ æ²’æœ‰ç­–ç•¥å»ºè­°")
        return
    
    for i, rec in enumerate(recommendations, 1):
        priority_color = {
            "High": "ğŸ”´",
            "Medium": "ğŸŸ¡",
            "Low": "ğŸŸ¢"
        }.get(rec.get("priority", "Medium"), "ğŸŸ¡")
        
        st.markdown(f"""
        ### {priority_color} {rec.get("strategy", "Unknown Strategy")}
        **æè¿°**: {rec.get("description", "No description")}
        **å„ªå…ˆç´š**: {rec.get("priority", "Medium")}
        **æ™‚é–“ç·š**: {rec.get("timeline", "Unknown")}
        **é æœŸå½±éŸ¿**: {rec.get("expected_impact", "Unknown")}
        
        **å¯¦æ–½æ­¥é©Ÿ**:
        """)
        
        steps = rec.get("implementation_steps", [])
        for step in steps:
            st.markdown(f"- {step}")

def display_eeat_detailed_results(result: Dict):
    """é¡¯ç¤ºè©³ç´° E-E-A-T çµæœ"""
    # é€™è£¡å¯ä»¥æ·»åŠ æ›´è©³ç´°çš„ E-E-A-T çµæœé¡¯ç¤º
    st.json(result)

def save_analysis_result(module: str, website: str, result: Dict):
    """å„²å­˜åˆ†æçµæœ"""
    # é€™è£¡å¯ä»¥å¯¦ç¾çµæœå„²å­˜é‚è¼¯
    pass

def load_analysis_reports():
    """è¼‰å…¥åˆ†æå ±å‘Š"""
    # é€™è£¡å¯ä»¥å¯¦ç¾å ±å‘Šè¼‰å…¥é‚è¼¯
    return []

if __name__ == "__main__":
    main() 